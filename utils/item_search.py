#!/usr/bin/env python3
"""
é—²é±¼å•†å“æœç´¢æ¨¡å—
åŸºäº Playwright å®ç°çœŸå®çš„é—²é±¼å•†å“æœç´¢åŠŸèƒ½
"""

import asyncio
import json
import time
import sys
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from loguru import logger

# ä¿®å¤Dockerç¯å¢ƒä¸­çš„asyncioäº‹ä»¶å¾ªç¯ç­–ç•¥é—®é¢˜
if sys.platform.startswith('linux') or os.getenv('DOCKER_ENV'):
    try:
        # åœ¨Linux/Dockerç¯å¢ƒä¸­è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥
        asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())
    except Exception as e:
        logger.warning(f"è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥å¤±è´¥: {e}")

# ç¡®ä¿åœ¨Dockerç¯å¢ƒä¸­ä½¿ç”¨æ­£ç¡®çš„äº‹ä»¶å¾ªç¯
if os.getenv('DOCKER_ENV'):
    try:
        # å¼ºåˆ¶ä½¿ç”¨SelectorEventLoopï¼ˆåœ¨Dockerä¸­æ›´ç¨³å®šï¼‰
        if hasattr(asyncio, 'SelectorEventLoop'):
            loop = asyncio.SelectorEventLoop()
            asyncio.set_event_loop(loop)
    except Exception as e:
        logger.warning(f"è®¾ç½®SelectorEventLoopå¤±è´¥: {e}")

try:
    from playwright.async_api import async_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    logger.warning("Playwright æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")


class XianyuSearcher:
    """é—²é±¼å•†å“æœç´¢å™¨ - åŸºäº Playwright"""

    def __init__(self):
        self.browser = None
        self.context = None
        self.page = None
        self.api_responses = []

    async def safe_get(self, data, *keys, default="æš‚æ— "):
        """å®‰å…¨è·å–åµŒå¥—å­—å…¸å€¼"""
        for key in keys:
            try:
                data = data[key]
            except (KeyError, TypeError, IndexError):
                return default
        return data

    async def test_browser_launch(self):
        """æµ‹è¯•æµè§ˆå™¨æ˜¯å¦èƒ½æ­£å¸¸å¯åŠ¨"""
        try:
            if not PLAYWRIGHT_AVAILABLE:
                return False, "Playwright æœªå®‰è£…"

            playwright = await async_playwright().start()
            browser = await playwright.chromium.launch(headless=True)
            context = await browser.new_context()
            page = await context.new_page()
            await page.goto("https://www.baidu.com")
            await asyncio.sleep(2)
            await browser.close()
            return True, "æµè§ˆå™¨æµ‹è¯•æˆåŠŸ"
        except Exception as e:
            return False, f"æµè§ˆå™¨æµ‹è¯•å¤±è´¥: {str(e)}"

    async def get_first_valid_cookie(self):
        """è·å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„cookie"""
        try:
            from db_manager import db_manager

            # è·å–æ‰€æœ‰cookiesï¼Œè¿”å›æ ¼å¼æ˜¯ {id: value}
            cookies = db_manager.get_all_cookies()

            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„cookieï¼ˆé•¿åº¦å¤§äº50çš„è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„ï¼‰
            for cookie_id, cookie_value in cookies.items():
                if len(cookie_value) > 50:
                    logger.info(f"æ‰¾åˆ°æœ‰æ•ˆcookie: {cookie_id}")
                    return {
                        'id': cookie_id,
                        'value': cookie_value
                    }

            return None

        except Exception as e:
            logger.error(f"è·å–cookieå¤±è´¥: {str(e)}")
            return None

    async def set_browser_cookies(self, cookie_value: str):
        """è®¾ç½®æµè§ˆå™¨cookies"""
        try:
            if not cookie_value:
                return False

            # è§£æcookieå­—ç¬¦ä¸²
            cookies = []
            for cookie_pair in cookie_value.split(';'):
                cookie_pair = cookie_pair.strip()
                if '=' in cookie_pair:
                    name, value = cookie_pair.split('=', 1)
                    cookies.append({
                        'name': name.strip(),
                        'value': value.strip(),
                        'domain': '.goofish.com',
                        'path': '/'
                    })

            # è®¾ç½®cookiesåˆ°æµè§ˆå™¨
            await self.context.add_cookies(cookies)
            logger.info(f"æˆåŠŸè®¾ç½® {len(cookies)} ä¸ªcookiesåˆ°æµè§ˆå™¨")
            return True

        except Exception as e:
            logger.error(f"è®¾ç½®æµè§ˆå™¨cookieså¤±è´¥: {str(e)}")
            return False

    async def init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        if not PLAYWRIGHT_AVAILABLE:
            raise Exception("Playwright æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨çœŸå®æœç´¢åŠŸèƒ½")

        if not self.browser:
            playwright = await async_playwright().start()
            logger.info("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
            # ç®€åŒ–çš„æµè§ˆå™¨å¯åŠ¨å‚æ•°ï¼Œé¿å…å†²çª
            browser_args = [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--no-first-run',
                '--disable-extensions',
                '--disable-default-apps',
                '--no-default-browser-check'
            ]

            # åªåœ¨ç¡®å®æ˜¯Dockerç¯å¢ƒæ—¶æ·»åŠ é¢å¤–å‚æ•°
            if os.getenv('DOCKER_ENV') == 'true':
                browser_args.extend([
                    '--disable-gpu',
                    '--single-process'
                ])

            logger.info("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
            self.browser = await playwright.chromium.launch(
                headless=True,  # æ— å¤´æ¨¡å¼ï¼Œåå°è¿è¡Œ
                args=browser_args
            )

            logger.info("æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼Œåˆ›å»ºä¸Šä¸‹æ–‡...")
            # ç®€åŒ–ä¸Šä¸‹æ–‡åˆ›å»ºï¼Œå‡å°‘å¯èƒ½çš„é—®é¢˜
            self.context = await self.browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                viewport={'width': 1280, 'height': 720}
            )

            logger.info("åˆ›å»ºé¡µé¢...")
            self.page = await self.context.new_page()

            logger.info("æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")

    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
            self.browser = None
            self.context = None
            self.page = None
    
    async def search_items(self, keyword: str, page: int = 1, page_size: int = 20) -> Dict[str, Any]:
        """
        æœç´¢é—²é±¼å•†å“ - ä½¿ç”¨ Playwright è·å–çœŸå®æ•°æ®

        Args:
            keyword: æœç´¢å…³é”®è¯
            page: é¡µç ï¼Œä»1å¼€å§‹
            page_size: æ¯é¡µæ•°é‡

        Returns:
            æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«itemsåˆ—è¡¨å’Œæ€»æ•°
        """
        try:
            if not PLAYWRIGHT_AVAILABLE:
                logger.error("Playwright ä¸å¯ç”¨ï¼Œæ— æ³•è·å–çœŸå®æ•°æ®")
                return {
                    'items': [],
                    'total': 0,
                    'error': 'Playwright ä¸å¯ç”¨ï¼Œæ— æ³•è·å–çœŸå®æ•°æ®'
                }

            logger.info(f"ä½¿ç”¨ Playwright æœç´¢é—²é±¼å•†å“: å…³é”®è¯='{keyword}', é¡µç ={page}, æ¯é¡µ={page_size}")

            await self.init_browser()

            # æ¸…ç©ºä¹‹å‰çš„APIå“åº”
            self.api_responses = []
            data_list = []

            # è®¾ç½®APIå“åº”ç›‘å¬å™¨
            async def on_response(response):
                """å¤„ç†APIå“åº”ï¼Œè§£ææ•°æ®"""
                if "h5api.m.goofish.com/h5/mtop.taobao.idlemtopsearch.pc.search" in response.url:
                    try:
                        # æ£€æŸ¥å“åº”çŠ¶æ€
                        if response.status != 200:
                            logger.warning(f"APIå“åº”çŠ¶æ€å¼‚å¸¸: {response.status}")
                            return

                        # å®‰å…¨åœ°è·å–å“åº”å†…å®¹
                        try:
                            result_json = await response.json()
                        except Exception as json_error:
                            logger.warning(f"æ— æ³•è§£æå“åº”JSON: {str(json_error)}")
                            return

                        self.api_responses.append(result_json)
                        logger.info(f"æ•è·åˆ°APIå“åº”ï¼ŒURL: {response.url}")

                        items = result_json.get("data", {}).get("resultList", [])
                        logger.info(f"ä»APIè·å–åˆ° {len(items)} æ¡åŸå§‹æ•°æ®")

                        for item in items:
                            try:
                                parsed_item = await self._parse_real_item(item)
                                if parsed_item:
                                    data_list.append(parsed_item)
                            except Exception as parse_error:
                                logger.warning(f"è§£æå•ä¸ªå•†å“å¤±è´¥: {str(parse_error)}")
                                continue

                    except Exception as e:
                        logger.warning(f"å“åº”å¤„ç†å¼‚å¸¸: {str(e)}")

            try:
                # è·å–å¹¶è®¾ç½®cookiesè¿›è¡Œç™»å½•
                logger.info("æ­£åœ¨è·å–æœ‰æ•ˆçš„cookiesè´¦æˆ·...")
                cookie_data = await self.get_first_valid_cookie()
                if not cookie_data:
                    raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„cookiesè´¦æˆ·ï¼Œè¯·å…ˆåœ¨Cookieç®¡ç†ä¸­æ·»åŠ æœ‰æ•ˆçš„é—²é±¼è´¦æˆ·")

                logger.info(f"ä½¿ç”¨è´¦æˆ·: {cookie_data.get('id', 'unknown')}")

                logger.info("æ­£åœ¨è®¿é—®é—²é±¼é¦–é¡µ...")
                await self.page.goto("https://www.goofish.com", timeout=30000)

                # è®¾ç½®cookiesè¿›è¡Œç™»å½•
                logger.info("æ­£åœ¨è®¾ç½®cookiesè¿›è¡Œç™»å½•...")
                cookie_success = await self.set_browser_cookies(cookie_data.get('value', ''))
                if not cookie_success:
                    logger.warning("è®¾ç½®cookieså¤±è´¥ï¼Œå°†ä»¥æœªç™»å½•çŠ¶æ€ç»§ç»­")
                else:
                    logger.info("âœ… cookiesè®¾ç½®æˆåŠŸï¼Œå·²ç™»å½•")
                    # åˆ·æ–°é¡µé¢ä»¥åº”ç”¨cookies
                    await self.page.reload()
                    await asyncio.sleep(2)

                await self.page.wait_for_load_state("networkidle", timeout=10000)

                logger.info(f"æ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")
                await self.page.fill('input[class*="search-input"]', keyword)

                # æ³¨å†Œå“åº”ç›‘å¬
                self.page.on("response", on_response)

                await self.page.click('button[type="submit"]')
                await self.page.wait_for_load_state("networkidle", timeout=15000)

                # ç­‰å¾…ç¬¬ä¸€é¡µAPIå“åº”
                logger.info("ç­‰å¾…ç¬¬ä¸€é¡µAPIå“åº”...")
                await asyncio.sleep(5)

                # å°è¯•å¤„ç†å¼¹çª—
                try:
                    await self.page.keyboard.press('Escape')
                    await asyncio.sleep(1)
                except:
                    pass

                # ç­‰å¾…æ›´å¤šæ•°æ®
                await asyncio.sleep(3)

                first_page_count = len(data_list)
                logger.info(f"ç¬¬1é¡µå®Œæˆï¼Œè·å–åˆ° {first_page_count} æ¡æ•°æ®")

                # å¦‚æœéœ€è¦è·å–æŒ‡å®šé¡µæ•°æ®ï¼Œå®ç°ç¿»é¡µé€»è¾‘
                if page > 1:
                    # æ¸…ç©ºä¹‹å‰çš„æ•°æ®ï¼Œåªä¿ç•™ç›®æ ‡é¡µçš„æ•°æ®
                    data_list.clear()
                    await self._navigate_to_page(page)

                # æ ¹æ®"äººæƒ³è¦"æ•°é‡è¿›è¡Œå€’åºæ’åˆ—
                data_list.sort(key=lambda x: x.get('want_count', 0), reverse=True)

                total_count = len(data_list)
                logger.info(f"æœç´¢å®Œæˆï¼Œæ€»å…±è·å–åˆ° {total_count} æ¡çœŸå®æ•°æ®ï¼Œå·²æŒ‰æƒ³è¦äººæ•°æ’åº")

                return {
                    'items': data_list,
                    'total': total_count,
                    'is_real_data': True,
                    'source': 'playwright'
                }

            finally:
                await self.close_browser()

        except Exception as e:
            error_msg = str(e)
            logger.error(f"Playwright æœç´¢å¤±è´¥: {error_msg}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æµè§ˆå™¨å®‰è£…é—®é¢˜
            if "Executable doesn't exist" in error_msg or "playwright install" in error_msg:
                error_msg = "æµè§ˆå™¨æœªå®‰è£…ã€‚è¯·åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ: playwright install chromium"
            elif "BrowserType.launch" in error_msg:
                error_msg = "æµè§ˆå™¨å¯åŠ¨å¤±è´¥ã€‚è¯·ç¡®ä¿Dockerå®¹å™¨æœ‰è¶³å¤Ÿçš„æƒé™å’Œèµ„æº"

            # å¦‚æœ Playwright å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            return {
                'items': [],
                'total': 0,
                'error': f'æœç´¢å¤±è´¥: {error_msg}'
            }

    async def _get_fallback_data(self, keyword: str, page: int, page_size: int) -> Dict[str, Any]:
        """è·å–å¤‡é€‰æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰"""
        logger.info(f"ä½¿ç”¨å¤‡é€‰æ•°æ®: å…³é”®è¯='{keyword}', é¡µç ={page}, æ¯é¡µ={page_size}")

        # æ¨¡æ‹Ÿæœç´¢å»¶è¿Ÿ
        await asyncio.sleep(0.5)

        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        mock_items = []
        start_index = (page - 1) * page_size

        for i in range(page_size):
            item_index = start_index + i + 1
            mock_items.append({
                'item_id': f'mock_{keyword}_{item_index}',
                'title': f'{keyword}ç›¸å…³å•†å“ #{item_index} [æ¨¡æ‹Ÿæ•°æ®]',
                'price': f'{100 + item_index * 10}',
                'seller_name': f'å–å®¶{item_index}',
                'item_url': f'https://www.goofish.com/item?id=mock_{keyword}_{item_index}',
                'publish_time': '2025-07-28',
                'tags': [f'æ ‡ç­¾{i+1}', f'åˆ†ç±»{i+1}'],
                'main_image': f'https://via.placeholder.com/200x200?text={keyword}å•†å“{item_index}',
                'raw_data': {
                    'mock': True,
                    'keyword': keyword,
                    'index': item_index
                }
            })

        # æ¨¡æ‹Ÿæ€»æ•°
        total_items = 100 + hash(keyword) % 500

        logger.info(f"å¤‡é€‰æ•°æ®ç”Ÿæˆå®Œæˆ: æ‰¾åˆ°{len(mock_items)}ä¸ªå•†å“ï¼Œæ€»è®¡{total_items}ä¸ª")

        return {
            'items': mock_items,
            'total': total_items,
            'is_fallback': True
        }

    async def _parse_real_item(self, item_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è§£æçœŸå®çš„é—²é±¼å•†å“æ•°æ®"""
        try:
            main_data = await self.safe_get(item_data, "data", "item", "main", "exContent", default={})
            click_params = await self.safe_get(item_data, "data", "item", "main", "clickParam", "args", default={})

            # è§£æå•†å“ä¿¡æ¯
            title = await self.safe_get(main_data, "title", default="æœªçŸ¥æ ‡é¢˜")

            # ä»·æ ¼å¤„ç†
            price_parts = await self.safe_get(main_data, "price", default=[])
            price = "ä»·æ ¼å¼‚å¸¸"
            if isinstance(price_parts, list):
                price = "".join([str(p.get("text", "")) for p in price_parts if isinstance(p, dict)])
                price = price.replace("å½“å‰ä»·", "").strip()

                # ç»Ÿä¸€ä»·æ ¼æ ¼å¼å¤„ç†
                if price and price != "ä»·æ ¼å¼‚å¸¸":
                    # å…ˆç§»é™¤æ‰€æœ‰Â¥ç¬¦å·ï¼Œé¿å…é‡å¤
                    clean_price = price.replace('Â¥', '').strip()

                    # å¤„ç†ä¸‡å•ä½çš„ä»·æ ¼
                    if "ä¸‡" in clean_price:
                        try:
                            numeric_price = clean_price.replace('ä¸‡', '').strip()
                            price_value = float(numeric_price) * 10000
                            price = f"Â¥{price_value:.0f}"
                        except:
                            price = f"Â¥{clean_price}"  # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·ä½†ç¡®ä¿æœ‰Â¥ç¬¦å·
                    else:
                        # æ™®é€šä»·æ ¼ï¼Œç¡®ä¿æœ‰Â¥ç¬¦å·
                        if clean_price and (clean_price[0].isdigit() or clean_price.replace('.', '').isdigit()):
                            price = f"Â¥{clean_price}"
                        else:
                            price = clean_price if clean_price else "ä»·æ ¼å¼‚å¸¸"

            # åªæå–"æƒ³è¦äººæ•°"æ ‡ç­¾
            fish_tags_content = ""
            fish_tags = await self.safe_get(main_data, "fishTags", default={})

            # éå†æ‰€æœ‰ç±»å‹çš„æ ‡ç­¾ (r2, r3, r4ç­‰)
            for tag_type, tag_data in fish_tags.items():
                if isinstance(tag_data, dict) and "tagList" in tag_data:
                    tag_list = tag_data.get("tagList", [])
                    for tag_item in tag_list:
                        if isinstance(tag_item, dict) and "data" in tag_item:
                            content = tag_item["data"].get("content", "")
                            # åªä¿ç•™åŒ…å«"äººæƒ³è¦"çš„æ ‡ç­¾
                            if content and "äººæƒ³è¦" in content:
                                fish_tags_content = content
                                break
                    if fish_tags_content:  # æ‰¾åˆ°åå°±é€€å‡º
                        break

            # å…¶ä»–å­—æ®µè§£æ
            area = await self.safe_get(main_data, "area", default="åœ°åŒºæœªçŸ¥")
            seller = await self.safe_get(main_data, "userNickName", default="åŒ¿åå–å®¶")
            raw_link = await self.safe_get(item_data, "data", "item", "main", "targetUrl", default="")
            image_url = await self.safe_get(main_data, "picUrl", default="")

            # è·å–å•†å“ID
            item_id = await self.safe_get(click_params, "item_id", default="æœªçŸ¥ID")

            # å¤„ç†å‘å¸ƒæ—¶é—´
            publish_time = "æœªçŸ¥æ—¶é—´"
            publish_timestamp = click_params.get("publishTime", "")
            if publish_timestamp and publish_timestamp.isdigit():
                try:
                    publish_time = datetime.fromtimestamp(
                        int(publish_timestamp)/1000
                    ).strftime("%Y-%m-%d %H:%M")
                except:
                    pass

            # æå–"äººæƒ³è¦"çš„æ•°å­—ç”¨äºæ’åº
            want_count = self._extract_want_count(fish_tags_content)

            return {
                "item_id": item_id,
                "title": title,
                "price": price,
                "seller_name": seller,
                "item_url": raw_link.replace("fleamarket://", "https://www.goofish.com/"),
                "main_image": f"https:{image_url}" if image_url and not image_url.startswith("http") else image_url,
                "publish_time": publish_time,
                "tags": [fish_tags_content] if fish_tags_content else [],
                "area": area,
                "want_count": want_count,  # æ·»åŠ æƒ³è¦äººæ•°ç”¨äºæ’åº
                "raw_data": item_data
            }

        except Exception as e:
            logger.warning(f"è§£æçœŸå®å•†å“æ•°æ®å¤±è´¥: {str(e)}")
            return None

    def _extract_want_count(self, tags_content: str) -> int:
        """ä»æ ‡ç­¾å†…å®¹ä¸­æå–"äººæƒ³è¦"çš„æ•°å­—"""
        try:
            if not tags_content or "äººæƒ³è¦" not in tags_content:
                return 0

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å­—
            import re
            # åŒ¹é…ç±»ä¼¼ "123äººæƒ³è¦" æˆ– "1.2ä¸‡äººæƒ³è¦" çš„æ ¼å¼
            pattern = r'(\d+(?:\.\d+)?(?:ä¸‡)?)\s*äººæƒ³è¦'
            match = re.search(pattern, tags_content)

            if match:
                number_str = match.group(1)
                if 'ä¸‡' in number_str:
                    # å¤„ç†ä¸‡å•ä½
                    number = float(number_str.replace('ä¸‡', '')) * 10000
                    return int(number)
                else:
                    return int(float(number_str))

            return 0
        except Exception as e:
            logger.warning(f"æå–æƒ³è¦äººæ•°å¤±è´¥: {str(e)}")
            return 0

    async def _navigate_to_page(self, target_page: int):
        """å¯¼èˆªåˆ°æŒ‡å®šé¡µé¢"""
        try:
            logger.info(f"æ­£åœ¨å¯¼èˆªåˆ°ç¬¬ {target_page} é¡µ...")

            # ç­‰å¾…é¡µé¢ç¨³å®š
            await asyncio.sleep(2)

            # æŸ¥æ‰¾å¹¶ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®
            next_button_selectors = [
                '.search-page-tiny-arrow-right--oXVFaRao',  # ç”¨æˆ·æ‰¾åˆ°çš„æ­£ç¡®é€‰æ‹©å™¨
                '[class*="search-page-tiny-arrow-right"]',  # æ›´é€šç”¨çš„ç‰ˆæœ¬
                'button[aria-label="ä¸‹ä¸€é¡µ"]',
                'button:has-text("ä¸‹ä¸€é¡µ")',
                'a:has-text("ä¸‹ä¸€é¡µ")',
                '.ant-pagination-next',
                'li.ant-pagination-next a',
                'a[aria-label="ä¸‹ä¸€é¡µ"]',
                '[class*="next"]',
                '[class*="pagination-next"]',
                'button[title="ä¸‹ä¸€é¡µ"]',
                'a[title="ä¸‹ä¸€é¡µ"]'
            ]

            # ä»ç¬¬2é¡µå¼€å§‹ç‚¹å‡»
            for current_page in range(2, target_page + 1):
                logger.info(f"æ­£åœ¨ç‚¹å‡»åˆ°ç¬¬ {current_page} é¡µ...")

                next_button_found = False
                for selector in next_button_selectors:
                    try:
                        next_button = self.page.locator(selector).first

                        if await next_button.is_visible(timeout=3000):
                            # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç‚¹å‡»ï¼ˆä¸æ˜¯ç¦ç”¨çŠ¶æ€ï¼‰
                            is_disabled = await next_button.get_attribute("disabled")
                            has_disabled_class = await next_button.evaluate("el => el.classList.contains('ant-pagination-disabled') || el.classList.contains('disabled')")

                            if not is_disabled and not has_disabled_class:
                                logger.info(f"æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œæ­£åœ¨ç‚¹å‡»...")

                                # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                                await next_button.scroll_into_view_if_needed()
                                await asyncio.sleep(1)

                                # ç‚¹å‡»ä¸‹ä¸€é¡µ
                                await next_button.click()
                                await self.page.wait_for_load_state("networkidle", timeout=15000)

                                # ç­‰å¾…æ–°æ•°æ®åŠ è½½
                                await asyncio.sleep(5)

                                logger.info(f"æˆåŠŸå¯¼èˆªåˆ°ç¬¬ {current_page} é¡µ")
                                next_button_found = True
                                break

                    except Exception as e:
                        continue

                if not next_button_found:
                    logger.warning(f"æ— æ³•æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œåœæ­¢åœ¨ç¬¬ {current_page-1} é¡µ")
                    break

        except Exception as e:
            logger.error(f"å¯¼èˆªåˆ°ç¬¬ {target_page} é¡µå¤±è´¥: {str(e)}")

    async def search_multiple_pages(self, keyword: str, total_pages: int = 1) -> Dict[str, Any]:
        """
        æœç´¢å¤šé¡µé—²é±¼å•†å“

        Args:
            keyword: æœç´¢å…³é”®è¯
            total_pages: æ€»é¡µæ•°

        Returns:
            æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰é¡µé¢çš„itemsåˆ—è¡¨å’Œæ€»æ•°
        """
        browser_initialized = False
        try:
            if not PLAYWRIGHT_AVAILABLE:
                logger.error("Playwright ä¸å¯ç”¨ï¼Œæ— æ³•è·å–çœŸå®æ•°æ®")
                return {
                    'items': [],
                    'total': 0,
                    'error': 'Playwright ä¸å¯ç”¨ï¼Œæ— æ³•è·å–çœŸå®æ•°æ®'
                }

            logger.info(f"ä½¿ç”¨ Playwright æœç´¢å¤šé¡µé—²é±¼å•†å“: å…³é”®è¯='{keyword}', æ€»é¡µæ•°={total_pages}")

            # ç¡®ä¿æµè§ˆå™¨åˆå§‹åŒ–
            await self.init_browser()
            browser_initialized = True

            # éªŒè¯æµè§ˆå™¨çŠ¶æ€
            if not self.browser or not self.page:
                raise Exception("æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥")

            logger.info("æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹æœç´¢...")

            # æ¸…ç©ºä¹‹å‰çš„APIå“åº”
            self.api_responses = []
            all_data_list = []

            # è®¾ç½®APIå“åº”ç›‘å¬å™¨
            async def on_response(response):
                """å¤„ç†APIå“åº”ï¼Œè§£ææ•°æ®"""
                if "h5api.m.goofish.com/h5/mtop.taobao.idlemtopsearch.pc.search" in response.url:
                    try:
                        # æ£€æŸ¥å“åº”çŠ¶æ€
                        if response.status != 200:
                            logger.warning(f"APIå“åº”çŠ¶æ€å¼‚å¸¸: {response.status}")
                            return

                        # å®‰å…¨åœ°è·å–å“åº”å†…å®¹
                        try:
                            result_json = await response.json()
                        except Exception as json_error:
                            logger.warning(f"æ— æ³•è§£æå“åº”JSON: {str(json_error)}")
                            return

                        self.api_responses.append(result_json)
                        logger.info(f"æ•è·åˆ°APIå“åº”ï¼ŒURL: {response.url}")

                        items = result_json.get("data", {}).get("resultList", [])
                        logger.info(f"ä»APIè·å–åˆ° {len(items)} æ¡åŸå§‹æ•°æ®")

                        for item in items:
                            try:
                                parsed_item = await self._parse_real_item(item)
                                if parsed_item:
                                    all_data_list.append(parsed_item)
                            except Exception as parse_error:
                                logger.warning(f"è§£æå•ä¸ªå•†å“å¤±è´¥: {str(parse_error)}")
                                continue

                    except Exception as e:
                        logger.warning(f"å“åº”å¤„ç†å¼‚å¸¸: {str(e)}")

            try:
                # æ£€æŸ¥æµè§ˆå™¨çŠ¶æ€
                if not self.page or self.page.is_closed():
                    raise Exception("é¡µé¢å·²å…³é—­æˆ–ä¸å¯ç”¨")

                # è·å–å¹¶è®¾ç½®cookiesè¿›è¡Œç™»å½•
                logger.info("æ­£åœ¨è·å–æœ‰æ•ˆçš„cookiesè´¦æˆ·...")
                cookie_data = await self.get_first_valid_cookie()
                if not cookie_data:
                    raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„cookiesè´¦æˆ·ï¼Œè¯·å…ˆåœ¨Cookieç®¡ç†ä¸­æ·»åŠ æœ‰æ•ˆçš„é—²é±¼è´¦æˆ·")

                logger.info(f"ä½¿ç”¨è´¦æˆ·: {cookie_data.get('id', 'unknown')}")

                logger.info("æ­£åœ¨è®¿é—®é—²é±¼é¦–é¡µ...")
                await self.page.goto("https://www.goofish.com", timeout=30000)

                # è®¾ç½®cookiesè¿›è¡Œç™»å½•
                logger.info("æ­£åœ¨è®¾ç½®cookiesè¿›è¡Œç™»å½•...")
                cookie_success = await self.set_browser_cookies(cookie_data.get('value', ''))
                if not cookie_success:
                    logger.warning("è®¾ç½®cookieså¤±è´¥ï¼Œå°†ä»¥æœªç™»å½•çŠ¶æ€ç»§ç»­")
                else:
                    logger.info("âœ… cookiesè®¾ç½®æˆåŠŸï¼Œå·²ç™»å½•")
                    # åˆ·æ–°é¡µé¢ä»¥åº”ç”¨cookies
                    await self.page.reload()
                    await asyncio.sleep(2)

                # å†æ¬¡æ£€æŸ¥é¡µé¢çŠ¶æ€
                if self.page.is_closed():
                    raise Exception("é¡µé¢åœ¨å¯¼èˆªåè¢«å…³é—­")

                logger.info("ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ...")
                await self.page.wait_for_load_state("networkidle", timeout=15000)

                # ç­‰å¾…é¡µé¢ç¨³å®š
                logger.info("ç­‰å¾…é¡µé¢ç¨³å®š...")
                await asyncio.sleep(3)  # å¢åŠ ç­‰å¾…æ—¶é—´

                # å†æ¬¡æ£€æŸ¥é¡µé¢çŠ¶æ€
                if self.page.is_closed():
                    raise Exception("é¡µé¢åœ¨ç­‰å¾…åŠ è½½åè¢«å…³é—­")

                # è·å–é¡µé¢æ ‡é¢˜å’ŒURLç”¨äºè°ƒè¯•
                page_title = await self.page.title()
                page_url = self.page.url
                logger.info(f"å½“å‰é¡µé¢æ ‡é¢˜: {page_title}")
                logger.info(f"å½“å‰é¡µé¢URL: {page_url}")

                logger.info(f"æ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")

                # å°è¯•å¤šç§æœç´¢æ¡†é€‰æ‹©å™¨
                search_selectors = [
                    'input[class*="search-input"]',
                    'input[placeholder*="æœç´¢"]',
                    'input[type="text"]',
                    '.search-input',
                    '#search-input'
                ]

                search_input = None
                for selector in search_selectors:
                    try:
                        logger.info(f"å°è¯•æŸ¥æ‰¾æœç´¢æ¡†ï¼Œé€‰æ‹©å™¨: {selector}")
                        search_input = await self.page.wait_for_selector(selector, timeout=5000)
                        if search_input:
                            logger.info(f"âœ… æ‰¾åˆ°æœç´¢æ¡†ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                            break
                    except Exception as e:
                        logger.info(f"âŒ é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°æœç´¢æ¡†: {str(e)}")
                        continue

                if not search_input:
                    raise Exception("æœªæ‰¾åˆ°æœç´¢æ¡†å…ƒç´ ")

                # æ£€æŸ¥é¡µé¢çŠ¶æ€
                if self.page.is_closed():
                    raise Exception("é¡µé¢åœ¨æŸ¥æ‰¾æœç´¢æ¡†åè¢«å…³é—­")

                await search_input.fill(keyword)
                logger.info(f"âœ… æœç´¢å…³é”®è¯ '{keyword}' å·²å¡«å…¥æœç´¢æ¡†")

                # æ³¨å†Œå“åº”ç›‘å¬
                self.page.on("response", on_response)

                logger.info("ğŸ–±ï¸ å‡†å¤‡ç‚¹å‡»æœç´¢æŒ‰é’®...")
                await self.page.click('button[type="submit"]')
                logger.info("âœ… æœç´¢æŒ‰é’®å·²ç‚¹å‡»")
                await self.page.wait_for_load_state("networkidle", timeout=15000)

                # ç­‰å¾…ç¬¬ä¸€é¡µAPIå“åº”
                logger.info("ç­‰å¾…ç¬¬ä¸€é¡µAPIå“åº”...")
                await asyncio.sleep(10)  # å¢åŠ ç­‰å¾…æ—¶é—´

                # å°è¯•å¤„ç†å¼¹çª—
                try:
                    await self.page.keyboard.press('Escape')
                    await asyncio.sleep(1)
                except:
                    pass

                # ç­‰å¾…æ›´å¤šæ•°æ®
                await asyncio.sleep(3)

                first_page_count = len(all_data_list)
                logger.info(f"ç¬¬1é¡µå®Œæˆï¼Œè·å–åˆ° {first_page_count} æ¡æ•°æ®")

                # å¦‚æœéœ€è¦è·å–æ›´å¤šé¡µæ•°æ®
                if total_pages > 1:
                    for page_num in range(2, total_pages + 1):
                        logger.info(f"æ­£åœ¨è·å–ç¬¬ {page_num} é¡µæ•°æ®...")

                        # ç­‰å¾…é¡µé¢ç¨³å®š
                        await asyncio.sleep(2)

                        # æŸ¥æ‰¾å¹¶ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®
                        next_button_found = False
                        next_button_selectors = [
                            '.search-page-tiny-arrow-right--oXVFaRao',
                            '[class*="search-page-tiny-arrow-right"]',
                            'button[aria-label="ä¸‹ä¸€é¡µ"]',
                            'button:has-text("ä¸‹ä¸€é¡µ")',
                            'a:has-text("ä¸‹ä¸€é¡µ")',
                            '.ant-pagination-next',
                            'li.ant-pagination-next a',
                            'a[aria-label="ä¸‹ä¸€é¡µ"]'
                        ]

                        for selector in next_button_selectors:
                            try:
                                next_button = self.page.locator(selector).first

                                if await next_button.is_visible(timeout=3000):
                                    # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç‚¹å‡»
                                    is_disabled = await next_button.get_attribute("disabled")
                                    has_disabled_class = await next_button.evaluate("el => el.classList.contains('ant-pagination-disabled') || el.classList.contains('disabled')")

                                    if not is_disabled and not has_disabled_class:
                                        logger.info(f"æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œæ­£åœ¨ç‚¹å‡»åˆ°ç¬¬ {page_num} é¡µ...")

                                        # è®°å½•ç‚¹å‡»å‰çš„æ•°æ®é‡
                                        before_click_count = len(all_data_list)

                                        # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®å¹¶ç‚¹å‡»
                                        await next_button.scroll_into_view_if_needed()
                                        await asyncio.sleep(1)
                                        await next_button.click()
                                        await self.page.wait_for_load_state("networkidle", timeout=15000)

                                        # ç­‰å¾…æ–°æ•°æ®åŠ è½½
                                        await asyncio.sleep(5)

                                        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®
                                        after_click_count = len(all_data_list)
                                        new_items = after_click_count - before_click_count

                                        if new_items > 0:
                                            logger.info(f"ç¬¬ {page_num} é¡µæˆåŠŸï¼Œæ–°å¢ {new_items} æ¡æ•°æ®")
                                            next_button_found = True
                                            break
                                        else:
                                            logger.warning(f"ç¬¬ {page_num} é¡µç‚¹å‡»åæ²¡æœ‰æ–°æ•°æ®ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                                            next_button_found = False
                                            break

                            except Exception as e:
                                continue

                        if not next_button_found:
                            logger.warning(f"æ— æ³•è·å–ç¬¬ {page_num} é¡µæ•°æ®ï¼Œåœæ­¢åœ¨ç¬¬ {page_num-1} é¡µ")
                            break

                # æ ¹æ®"äººæƒ³è¦"æ•°é‡è¿›è¡Œå€’åºæ’åˆ—
                all_data_list.sort(key=lambda x: x.get('want_count', 0), reverse=True)

                total_count = len(all_data_list)
                logger.info(f"å¤šé¡µæœç´¢å®Œæˆï¼Œæ€»å…±è·å–åˆ° {total_count} æ¡çœŸå®æ•°æ®ï¼Œå·²æŒ‰æƒ³è¦äººæ•°æ’åº")

                return {
                    'items': all_data_list,
                    'total': total_count,
                    'is_real_data': True,
                    'source': 'playwright'
                }

            finally:
                # ç¡®ä¿æµè§ˆå™¨è¢«æ­£ç¡®å…³é—­
                if browser_initialized:
                    try:
                        await self.close_browser()
                        logger.info("æµè§ˆå™¨å·²å®‰å…¨å…³é—­")
                    except Exception as close_error:
                        logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {str(close_error)}")

        except Exception as e:
            error_msg = str(e)
            logger.error(f"Playwright å¤šé¡µæœç´¢å¤±è´¥: {error_msg}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æµè§ˆå™¨ç›¸å…³é—®é¢˜
            if "Executable doesn't exist" in error_msg or "playwright install" in error_msg:
                error_msg = "æµè§ˆå™¨æœªå®‰è£…ã€‚è¯·åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ: playwright install chromium"
            elif "BrowserType.launch" in error_msg:
                error_msg = "æµè§ˆå™¨å¯åŠ¨å¤±è´¥ã€‚è¯·ç¡®ä¿Dockerå®¹å™¨æœ‰è¶³å¤Ÿçš„æƒé™å’Œèµ„æº"
            elif "Target page, context or browser has been closed" in error_msg:
                error_msg = "æµè§ˆå™¨é¡µé¢è¢«æ„å¤–å…³é—­ã€‚è¿™å¯èƒ½æ˜¯ç”±äºç½‘ç«™åçˆ¬è™«æ£€æµ‹æˆ–ç³»ç»Ÿèµ„æºé™åˆ¶å¯¼è‡´çš„"
            elif "Page.goto" in error_msg and "closed" in error_msg:
                error_msg = "é¡µé¢å¯¼èˆªå¤±è´¥ï¼Œæµè§ˆå™¨è¿æ¥å·²æ–­å¼€"
            elif "Timeout" in error_msg and "exceeded" in error_msg:
                error_msg = "é¡µé¢åŠ è½½è¶…æ—¶ã€‚ç½‘ç»œè¿æ¥å¯èƒ½ä¸ç¨³å®šæˆ–ç½‘ç«™å“åº”ç¼“æ…¢"

            # å¦‚æœ Playwright å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            return {
                'items': [],
                'total': 0,
                'error': f'å¤šé¡µæœç´¢å¤±è´¥: {error_msg}'
            }

    async def _get_multiple_fallback_data(self, keyword: str, total_pages: int) -> Dict[str, Any]:
        """è·å–å¤šé¡µå¤‡é€‰æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰"""
        logger.info(f"ä½¿ç”¨å¤šé¡µå¤‡é€‰æ•°æ®: å…³é”®è¯='{keyword}', æ€»é¡µæ•°={total_pages}")

        # æ¨¡æ‹Ÿæœç´¢å»¶è¿Ÿ
        await asyncio.sleep(1)

        # ç”Ÿæˆå¤šé¡µæ¨¡æ‹Ÿæ•°æ®
        all_mock_items = []

        for page in range(1, total_pages + 1):
            page_size = 20  # æ¯é¡µ20æ¡
            start_index = (page - 1) * page_size

            for i in range(page_size):
                item_index = start_index + i + 1
                all_mock_items.append({
                    'item_id': f'mock_{keyword}_{item_index}',
                    'title': f'{keyword}ç›¸å…³å•†å“ #{item_index} [æ¨¡æ‹Ÿæ•°æ®-ç¬¬{page}é¡µ]',
                    'price': f'{100 + item_index * 10}',
                    'seller_name': f'å–å®¶{item_index}',
                    'item_url': f'https://www.goofish.com/item?id=mock_{keyword}_{item_index}',
                    'publish_time': '2025-07-28',
                    'tags': [f'æ ‡ç­¾{i+1}', f'åˆ†ç±»{i+1}'],
                    'main_image': f'https://via.placeholder.com/200x200?text={keyword}å•†å“{item_index}',
                    'raw_data': {
                        'mock': True,
                        'keyword': keyword,
                        'index': item_index,
                        'page': page
                    }
                })

        total_count = len(all_mock_items)
        logger.info(f"å¤šé¡µå¤‡é€‰æ•°æ®ç”Ÿæˆå®Œæˆ: æ‰¾åˆ°{total_count}ä¸ªå•†å“ï¼Œå…±{total_pages}é¡µ")

        return {
            'items': all_mock_items,
            'total': total_count,
            'is_fallback': True
        }




    async def _parse_item_old(self, item_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è§£æå•ä¸ªå•†å“æ•°æ®

        Args:
            item_data: å•†å“åŸå§‹æ•°æ®

        Returns:
            è§£æåçš„å•†å“ä¿¡æ¯
        """
        try:
            # åŸºæœ¬ä¿¡æ¯ - é€‚é…å¤šç§å¯èƒ½çš„å­—æ®µå
            item_id = (item_data.get('id') or
                      item_data.get('itemId') or
                      item_data.get('item_id') or
                      item_data.get('spuId') or '')

            title = (item_data.get('title') or
                    item_data.get('name') or
                    item_data.get('itemTitle') or
                    item_data.get('subject') or '')

            # ä»·æ ¼å¤„ç†
            price_raw = (item_data.get('price') or
                        item_data.get('priceText') or
                        item_data.get('currentPrice') or
                        item_data.get('realPrice') or '')

            # æ¸…ç†ä»·æ ¼æ ¼å¼
            if isinstance(price_raw, (int, float)):
                price = str(price_raw)
            elif isinstance(price_raw, str):
                price = price_raw.replace('Â¥', '').replace('å…ƒ', '').strip()
            else:
                price = 'ä»·æ ¼é¢è®®'

            # å–å®¶ä¿¡æ¯
            seller_info = (item_data.get('seller') or
                          item_data.get('user') or
                          item_data.get('owner') or {})

            seller_name = ''
            if seller_info:
                seller_name = (seller_info.get('nick') or
                              seller_info.get('nickname') or
                              seller_info.get('name') or
                              seller_info.get('userName') or 'åŒ¿åç”¨æˆ·')

            # å•†å“é“¾æ¥
            if item_id:
                item_url = f"https://www.goofish.com/item?id={item_id}"
            else:
                item_url = item_data.get('url', item_data.get('link', ''))

            # å‘å¸ƒæ—¶é—´
            publish_time = (item_data.get('publishTime') or
                           item_data.get('createTime') or
                           item_data.get('gmtCreate') or
                           item_data.get('time') or '')

            # æ ¼å¼åŒ–æ—¶é—´
            if publish_time and isinstance(publish_time, (int, float)):
                import datetime
                publish_time = datetime.datetime.fromtimestamp(publish_time / 1000).strftime('%Y-%m-%d')

            # å•†å“æ ‡ç­¾
            tags = item_data.get('tags', item_data.get('labels', []))
            tag_names = []
            if isinstance(tags, list):
                for tag in tags:
                    if isinstance(tag, dict):
                        tag_name = (tag.get('name') or
                                   tag.get('text') or
                                   tag.get('label') or '')
                        if tag_name:
                            tag_names.append(tag_name)
                    elif isinstance(tag, str):
                        tag_names.append(tag)

            # å›¾ç‰‡
            images = (item_data.get('images') or
                     item_data.get('pics') or
                     item_data.get('pictures') or
                     item_data.get('imgList') or [])

            main_image = ''
            if images and len(images) > 0:
                if isinstance(images[0], str):
                    main_image = images[0]
                elif isinstance(images[0], dict):
                    main_image = (images[0].get('url') or
                                 images[0].get('src') or
                                 images[0].get('image') or '')

            # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨é»˜è®¤å ä½å›¾
            if not main_image:
                main_image = f'https://via.placeholder.com/200x200?text={title[:10] if title else "å•†å“"}...'
            
            return {
                'item_id': item_id,
                'title': title,
                'price': price,
                'seller_name': seller_name,
                'item_url': item_url,
                'publish_time': publish_time,
                'tags': tag_names,
                'main_image': main_image,
                'raw_data': item_data  # ä¿ç•™åŸå§‹æ•°æ®ä»¥å¤‡åç”¨
            }
            
        except Exception as e:
            logger.warning(f"è§£æå•†å“æ•°æ®å¤±è´¥: {str(e)}")
            return None


# æœç´¢å™¨å·¥å…·å‡½æ•°

async def search_xianyu_items(keyword: str, page: int = 1, page_size: int = 20) -> Dict[str, Any]:
    """
    æœç´¢é—²é±¼å•†å“çš„ä¾¿æ·å‡½æ•°ï¼Œå¸¦é‡è¯•æœºåˆ¶

    Args:
        keyword: æœç´¢å…³é”®è¯
        page: é¡µç 
        page_size: æ¯é¡µæ•°é‡

    Returns:
        æœç´¢ç»“æœ
    """
    max_retries = 2
    retry_delay = 5  # ç§’ï¼Œå¢åŠ é‡è¯•é—´éš”

    for attempt in range(max_retries + 1):
        searcher = None
        try:
            # æ¯æ¬¡æœç´¢éƒ½åˆ›å»ºæ–°çš„æœç´¢å™¨å®ä¾‹ï¼Œé¿å…æµè§ˆå™¨çŠ¶æ€æ··ä¹±
            searcher = XianyuSearcher()

            logger.info(f"å¼€å§‹å•é¡µæœç´¢ï¼Œå°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries + 1}")
            result = await searcher.search_items(keyword, page, page_size)

            # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ï¼Œç›´æ¥è¿”å›
            if result.get('items') or not result.get('error'):
                logger.info(f"å•é¡µæœç´¢æˆåŠŸï¼Œè·å–åˆ° {len(result.get('items', []))} æ¡æ•°æ®")
                return result

        except Exception as e:
            error_msg = str(e)
            logger.error(f"æœç´¢å•†å“å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {error_msg}")

            # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›é”™è¯¯
            if attempt == max_retries:
                return {
                    'items': [],
                    'total': 0,
                    'error': f"æœç´¢å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {error_msg}"
                }

            # ç­‰å¾…åé‡è¯•
            logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
            await asyncio.sleep(retry_delay)

        finally:
            # ç¡®ä¿æœç´¢å™¨è¢«æ­£ç¡®å…³é—­
            if searcher:
                try:
                    await searcher.close_browser()
                except Exception as close_error:
                    logger.warning(f"å…³é—­æœç´¢å™¨æ—¶å‡ºé”™: {str(close_error)}")

    # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œ
    return {
        'items': [],
        'total': 0,
        'error': "æœªçŸ¥é”™è¯¯"
    }


async def search_multiple_pages_xianyu(keyword: str, total_pages: int = 1) -> Dict[str, Any]:
    """
    æœç´¢å¤šé¡µé—²é±¼å•†å“çš„ä¾¿æ·å‡½æ•°ï¼Œå¸¦é‡è¯•æœºåˆ¶

    Args:
        keyword: æœç´¢å…³é”®è¯
        total_pages: æ€»é¡µæ•°

    Returns:
        æœç´¢ç»“æœ
    """
    max_retries = 2
    retry_delay = 5  # ç§’ï¼Œå¢åŠ é‡è¯•é—´éš”

    for attempt in range(max_retries + 1):
        searcher = None
        try:
            # æ¯æ¬¡æœç´¢éƒ½åˆ›å»ºæ–°çš„æœç´¢å™¨å®ä¾‹ï¼Œé¿å…æµè§ˆå™¨çŠ¶æ€æ··ä¹±
            searcher = XianyuSearcher()

            logger.info(f"å¼€å§‹å¤šé¡µæœç´¢ï¼Œå°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries + 1}")
            result = await searcher.search_multiple_pages(keyword, total_pages)

            # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ï¼Œç›´æ¥è¿”å›
            if result.get('items') or not result.get('error'):
                logger.info(f"å¤šé¡µæœç´¢æˆåŠŸï¼Œè·å–åˆ° {len(result.get('items', []))} æ¡æ•°æ®")
                return result

        except Exception as e:
            error_msg = str(e)
            logger.error(f"å¤šé¡µæœç´¢å•†å“å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {error_msg}")

            # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›é”™è¯¯
            if attempt == max_retries:
                return {
                    'items': [],
                    'total': 0,
                    'error': f"æœç´¢å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {error_msg}"
                }

            # ç­‰å¾…åé‡è¯•
            logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
            await asyncio.sleep(retry_delay)

        finally:
            # ç¡®ä¿æœç´¢å™¨è¢«æ­£ç¡®å…³é—­
            if searcher:
                try:
                    await searcher.close_browser()
                except Exception as close_error:
                    logger.warning(f"å…³é—­æœç´¢å™¨æ—¶å‡ºé”™: {str(close_error)}")

    # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œ
    return {
        'items': [],
        'total': 0,
        'error': "æœªçŸ¥é”™è¯¯"
    }




async def get_item_detail_from_api(item_id: str) -> Optional[str]:
    """
    ä»å¤–éƒ¨APIè·å–å•†å“è¯¦æƒ…

    Args:
        item_id: å•†å“ID

    Returns:
        å•†å“è¯¦æƒ…æ–‡æœ¬ï¼Œè·å–å¤±è´¥è¿”å›None
    """
    try:
        # ä½¿ç”¨é»˜è®¤çš„APIé…ç½®
        api_base_url = 'https://selfapi.zhinianboke.com/api/getItemDetail'
        timeout_seconds = 10

        api_url = f"{api_base_url}/{item_id}"

        logger.info(f"æ­£åœ¨ä»å¤–éƒ¨APIè·å–å•†å“è¯¦æƒ…: {item_id}")

        # ä½¿ç”¨ç®€å•çš„HTTPè¯·æ±‚
        import aiohttp
        timeout = aiohttp.ClientTimeout(total=timeout_seconds)

        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(api_url) as response:
                if response.status == 200:
                    result = await response.json()

                    # æ£€æŸ¥è¿”å›çŠ¶æ€
                    if result.get('status') == '200' and result.get('data'):
                        item_detail = result['data']
                        logger.info(f"æˆåŠŸè·å–å•†å“è¯¦æƒ…: {item_id}, é•¿åº¦: {len(item_detail)}")
                        return item_detail
                    else:
                        logger.warning(f"APIè¿”å›çŠ¶æ€å¼‚å¸¸: {result.get('status')}, message: {result.get('message')}")
                        return None
                else:
                    logger.warning(f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status}")
                    return None

    except asyncio.TimeoutError:
        logger.warning(f"è·å–å•†å“è¯¦æƒ…è¶…æ—¶: {item_id}")
        return None
    except Exception as e:
        logger.error(f"è·å–å•†å“è¯¦æƒ…å¼‚å¸¸: {item_id}, é”™è¯¯: {str(e)}")
        return None
