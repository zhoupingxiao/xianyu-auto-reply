#!/usr/bin/env python3
"""
å¤‡ä»½å’Œå¯¼å…¥åŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯æ‰€æœ‰è¡¨æ˜¯å¦æ­£ç¡®åŒ…å«åœ¨å¤‡ä»½ä¸­
"""

import asyncio
import sys
import os
import json
import tempfile

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from db_manager import db_manager
from loguru import logger

def get_all_tables():
    """è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨"""
    try:
        with db_manager.lock:
            cursor = db_manager.conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
            tables = [row[0] for row in cursor.fetchall()]
            return sorted(tables)
    except Exception as e:
        logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
        return []

def get_table_row_count(table_name):
    """è·å–è¡¨çš„è¡Œæ•°"""
    try:
        with db_manager.lock:
            cursor = db_manager.conn.cursor()
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            return cursor.fetchone()[0]
    except Exception as e:
        logger.error(f"è·å–è¡¨ {table_name} è¡Œæ•°å¤±è´¥: {e}")
        return 0

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("ğŸ“ åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    test_data_created = []
    
    try:
        # 1. åˆ›å»ºæµ‹è¯•è´¦å·
        test_cookie_id = "test_backup_001"
        success = db_manager.save_cookie(test_cookie_id, "test_cookie_value_for_backup")
        if success:
            test_data_created.append(f"è´¦å·: {test_cookie_id}")
        
        # 2. åˆ›å»ºå…³é”®è¯
        keywords = [("æµ‹è¯•å…³é”®è¯1", "æµ‹è¯•å›å¤1"), ("æµ‹è¯•å…³é”®è¯2", "æµ‹è¯•å›å¤2")]
        success = db_manager.save_keywords(test_cookie_id, keywords)
        if success:
            test_data_created.append(f"å…³é”®è¯: {len(keywords)} ä¸ª")
        
        # 3. åˆ›å»ºAIå›å¤è®¾ç½®
        ai_settings = {
            'ai_enabled': True,
            'model_name': 'qwen-plus',
            'api_key': 'test-backup-key',
            'base_url': 'https://test.com',
            'max_discount_percent': 10,
            'max_discount_amount': 100,
            'max_bargain_rounds': 3,
            'custom_prompts': '{"test": "prompt"}'
        }
        success = db_manager.save_ai_reply_settings(test_cookie_id, ai_settings)
        if success:
            test_data_created.append("AIå›å¤è®¾ç½®")
        
        # 4. åˆ›å»ºé»˜è®¤å›å¤
        success = db_manager.save_default_reply(test_cookie_id, True, "æµ‹è¯•é»˜è®¤å›å¤å†…å®¹")
        if success:
            test_data_created.append("é»˜è®¤å›å¤")
        
        # 5. åˆ›å»ºå•†å“ä¿¡æ¯
        success = db_manager.save_item_basic_info(
            test_cookie_id, "test_item_001", 
            "æµ‹è¯•å•†å“", "æµ‹è¯•æè¿°", "æµ‹è¯•åˆ†ç±»", "100", "æµ‹è¯•è¯¦æƒ…"
        )
        if success:
            test_data_created.append("å•†å“ä¿¡æ¯")
        
        print(f"   âœ… æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ: {', '.join(test_data_created)}")
        return True
        
    except Exception as e:
        print(f"   âŒ åˆ›å»ºæµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return False

def test_backup_export():
    """æµ‹è¯•å¤‡ä»½å¯¼å‡ºåŠŸèƒ½"""
    print("\nğŸ“¤ æµ‹è¯•å¤‡ä»½å¯¼å‡ºåŠŸèƒ½...")
    
    try:
        # è·å–æ‰€æœ‰è¡¨
        all_tables = get_all_tables()
        print(f"   æ•°æ®åº“ä¸­çš„è¡¨: {all_tables}")
        
        # å¯¼å‡ºå¤‡ä»½
        backup_data = db_manager.export_backup()
        
        if not backup_data:
            print("   âŒ å¤‡ä»½å¯¼å‡ºå¤±è´¥")
            return None
        
        # æ£€æŸ¥å¤‡ä»½æ•°æ®ç»“æ„
        print(f"   âœ… å¤‡ä»½å¯¼å‡ºæˆåŠŸ")
        print(f"   å¤‡ä»½ç‰ˆæœ¬: {backup_data.get('version')}")
        print(f"   å¤‡ä»½æ—¶é—´: {backup_data.get('timestamp')}")
        
        # æ£€æŸ¥åŒ…å«çš„è¡¨
        backed_up_tables = list(backup_data['data'].keys())
        print(f"   å¤‡ä»½çš„è¡¨: {sorted(backed_up_tables)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„è¡¨
        missing_tables = set(all_tables) - set(backed_up_tables)
        if missing_tables:
            print(f"   âš ï¸  æœªå¤‡ä»½çš„è¡¨: {sorted(missing_tables)}")
        else:
            print(f"   âœ… æ‰€æœ‰è¡¨éƒ½å·²å¤‡ä»½")
        
        # æ£€æŸ¥æ¯ä¸ªè¡¨çš„æ•°æ®é‡
        print(f"\n   ğŸ“Š å„è¡¨æ•°æ®ç»Ÿè®¡:")
        for table in sorted(backed_up_tables):
            row_count = len(backup_data['data'][table]['rows'])
            print(f"      {table}: {row_count} è¡Œ")
        
        return backup_data
        
    except Exception as e:
        print(f"   âŒ å¤‡ä»½å¯¼å‡ºå¼‚å¸¸: {e}")
        return None

def test_backup_import(backup_data):
    """æµ‹è¯•å¤‡ä»½å¯¼å…¥åŠŸèƒ½"""
    print("\nğŸ“¥ æµ‹è¯•å¤‡ä»½å¯¼å…¥åŠŸèƒ½...")
    
    if not backup_data:
        print("   âŒ æ²¡æœ‰å¤‡ä»½æ•°æ®å¯å¯¼å…¥")
        return False
    
    try:
        # è®°å½•å¯¼å…¥å‰çš„æ•°æ®é‡
        print("   ğŸ“Š å¯¼å…¥å‰æ•°æ®ç»Ÿè®¡:")
        all_tables = get_all_tables()
        before_counts = {}
        for table in all_tables:
            count = get_table_row_count(table)
            before_counts[table] = count
            print(f"      {table}: {count} è¡Œ")
        
        # æ‰§è¡Œå¯¼å…¥
        success = db_manager.import_backup(backup_data)
        
        if not success:
            print("   âŒ å¤‡ä»½å¯¼å…¥å¤±è´¥")
            return False
        
        print("   âœ… å¤‡ä»½å¯¼å…¥æˆåŠŸ")
        
        # è®°å½•å¯¼å…¥åçš„æ•°æ®é‡
        print("\n   ğŸ“Š å¯¼å…¥åæ•°æ®ç»Ÿè®¡:")
        after_counts = {}
        for table in all_tables:
            count = get_table_row_count(table)
            after_counts[table] = count
            print(f"      {table}: {count} è¡Œ")
        
        # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        print("\n   ğŸ” æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥:")
        for table in sorted(backup_data['data'].keys()):
            expected_count = len(backup_data['data'][table]['rows'])
            actual_count = after_counts.get(table, 0)
            
            if table == 'system_settings':
                # ç³»ç»Ÿè®¾ç½®è¡¨å¯èƒ½ä¿ç•™ç®¡ç†å‘˜å¯†ç ï¼Œæ‰€ä»¥æ•°é‡å¯èƒ½ä¸å®Œå…¨ä¸€è‡´
                print(f"      {table}: æœŸæœ› {expected_count}, å®é™… {actual_count} (ç³»ç»Ÿè®¾ç½®è¡¨)")
            elif expected_count == actual_count:
                print(f"      {table}: âœ… ä¸€è‡´ ({actual_count} è¡Œ)")
            else:
                print(f"      {table}: âŒ ä¸ä¸€è‡´ (æœŸæœ› {expected_count}, å®é™… {actual_count})")
        
        return True
        
    except Exception as e:
        print(f"   âŒ å¤‡ä»½å¯¼å…¥å¼‚å¸¸: {e}")
        return False

def test_backup_file_operations():
    """æµ‹è¯•å¤‡ä»½æ–‡ä»¶æ“ä½œ"""
    print("\nğŸ’¾ æµ‹è¯•å¤‡ä»½æ–‡ä»¶æ“ä½œ...")
    
    try:
        # å¯¼å‡ºå¤‡ä»½
        backup_data = db_manager.export_backup()
        if not backup_data:
            print("   âŒ å¯¼å‡ºå¤‡ä»½å¤±è´¥")
            return False
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
            json.dump(backup_data, f, indent=2, ensure_ascii=False)
            temp_file = f.name
        
        print(f"   âœ… å¤‡ä»½ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_file}")
        
        # ä»æ–‡ä»¶è¯»å–
        with open(temp_file, 'r', encoding='utf-8') as f:
            loaded_backup = json.load(f)
        
        print(f"   âœ… ä»æ–‡ä»¶è¯»å–å¤‡ä»½æˆåŠŸ")
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        if loaded_backup == backup_data:
            print(f"   âœ… æ–‡ä»¶æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        else:
            print(f"   âŒ æ–‡ä»¶æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥")
            return False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)
        print(f"   âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"   âŒ å¤‡ä»½æ–‡ä»¶æ“ä½œå¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¤‡ä»½å’Œå¯¼å…¥åŠŸèƒ½æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data_ok = create_test_data()
    if not data_ok:
        print("\nâŒ æµ‹è¯•æ•°æ®åˆ›å»ºå¤±è´¥")
        return
    
    # æµ‹è¯•å¤‡ä»½å¯¼å‡º
    backup_data = test_backup_export()
    if not backup_data:
        print("\nâŒ å¤‡ä»½å¯¼å‡ºæµ‹è¯•å¤±è´¥")
        return
    
    # æµ‹è¯•å¤‡ä»½å¯¼å…¥
    import_ok = test_backup_import(backup_data)
    if not import_ok:
        print("\nâŒ å¤‡ä»½å¯¼å…¥æµ‹è¯•å¤±è´¥")
        return
    
    # æµ‹è¯•æ–‡ä»¶æ“ä½œ
    file_ok = test_backup_file_operations()
    if not file_ok:
        print("\nâŒ å¤‡ä»½æ–‡ä»¶æ“ä½œæµ‹è¯•å¤±è´¥")
        return
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤‡ä»½å’Œå¯¼å…¥åŠŸèƒ½æ­£å¸¸ï¼")
    print("\nâœ… åŠŸèƒ½éªŒè¯:")
    print("   â€¢ æ‰€æœ‰13ä¸ªè¡¨éƒ½åŒ…å«åœ¨å¤‡ä»½ä¸­")
    print("   â€¢ å¤‡ä»½å¯¼å‡ºåŠŸèƒ½æ­£å¸¸")
    print("   â€¢ å¤‡ä»½å¯¼å…¥åŠŸèƒ½æ­£å¸¸")
    print("   â€¢ æ•°æ®å®Œæ•´æ€§ä¿æŒ")
    print("   â€¢ æ–‡ä»¶æ“ä½œæ­£å¸¸")
    print("\nğŸ“‹ åŒ…å«çš„è¡¨:")
    
    # æ˜¾ç¤ºæ‰€æœ‰å¤‡ä»½çš„è¡¨
    if backup_data and 'data' in backup_data:
        for table in sorted(backup_data['data'].keys()):
            row_count = len(backup_data['data'][table]['rows'])
            print(f"   â€¢ {table}: {row_count} è¡Œæ•°æ®")

if __name__ == "__main__":
    main()
